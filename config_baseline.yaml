# MIDAS Baseline Classifier Configuration (No Early Exit Routing)
# This trains the backbone network only, routing will be added later

# Data configuration
data:
  # Use pre-split CICIDS2017 data
  train_path: "data/processed/train.csv"
  val_path: "data/processed/val.csv"
  test_path: "data/processed/test.csv"

  # Target column name in CSV
  target_column: "label"

  # Feature normalization
  normalize: true

  # Batch size
  batch_size: 512  # Larger batch for binary classification

  # Random seed
  random_seed: 42

# Model architecture
model:
  # Network type: "mlp"
  type: "mlp"

  # Input dimension (auto-detected from data: 78 features)
  # input_dim: 78

  # Hidden layer dimensions - 5 layer network
  hidden_dims: [256, 512, 512, 256, 128]

  # Exit layer indices (will add exit heads but not use them in baseline)
  exit_layers: [1, 3, 4]

  # Number of output classes (binary: BENIGN=0, ATTACK=1)
  num_classes: 2

  # Dropout rates
  dropout: 0.3  # Higher dropout for generalization
  exit_dropout: 0.2

# Routing module configuration
routing:
  # NO ROUTING for baseline training
  type: "none"

# Cost model configuration
cost:
  # Cost type: "layer_depth"
  type: "layer_depth"

  # Layer-specific costs (computational cost at each layer)
  cost_per_layer: [1.0, 2.0, 3.0, 4.0, 5.0]

  # Cost penalty weight (not used in baseline, but needed for validation)
  lambda: 0.1

# Training configuration
training:
  # Number of training epochs
  epochs: 50

  # Learning rates
  lr_classifier: 0.001
  lr_routing: 0.0  # Not used in baseline

  # Optimizer
  optimizer: "adamw"
  weight_decay: 0.0001

  # Learning rate schedule
  scheduler: "cosine"

  # Loss weights for each exit
  exit_loss_weights: [0.3, 0.5, 1.0]
  routing_loss_weight: 0.0  # No routing

  # RL training (disabled for baseline)
  rl:
    advantage_beta: 0.99
    entropy_coef: 0.01
    warmup_epochs: 50  # All epochs are warmup (no routing trained)

  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    metric: "val_overall_accuracy"

  # Gradient clipping
  grad_clip: 1.0

  # Device
  device: "mps"  # Use Apple Silicon GPU (change to "cuda" for NVIDIA or "cpu")

# Evaluation configuration
evaluation:
  # Oracle baselines to compare against
  oracle_baselines:
    - "always_final"  # Always use final exit (our baseline)

  # Metrics to compute
  metrics:
    - "accuracy"
    - "per_exit_accuracy"

# Weights & Biases configuration
wandb:
  enabled: true  # Disable for initial testing
  project: "MIDAS-CICIDS2017"
  entity: null

  run_name: "baseline_binary_classification"

  tags:
    - "baseline"
    - "no-routing"
    - "cicids2017"
    - "binary"

  log_interval: 50

  save_checkpoints: true
